"""
Лабораторна робота №9 — Нейро-нечіткі системи (ANFIS)
Автор : Y.4.N.
Мова : Python 3

Опис:
  Проста реалізація адаптивної нейро-нечіткої системи (ANFIS)
  для апроксимації функції y = sin(πx).
  Модель навчається за допомогою двох нечітких правил.
"""

import numpy as np
import matplotlib.pyplot as plt

# -------------------------------------------------------------
# 1. Функція приналежності (Гаусова)
# -------------------------------------------------------------
def gauss_mf(x, c, sigma):
    """Гаусова функція приналежності"""
    return np.exp(-0.5 * ((x - c) / sigma) ** 2)

# -------------------------------------------------------------
# 2. Генерація навчальних даних
# -------------------------------------------------------------
# Використаємо цільову функцію y = sin(πx)
X = np.linspace(0, 1, 100)
Y = np.sin(np.pi * X)

# -------------------------------------------------------------
# 3. Початкові параметри для двох нечітких правил
# -------------------------------------------------------------
# Антецедентні параметри (центри та ширини функцій приналежності)
c1, sigma1 = 0.25, 0.2
c2, sigma2 = 0.75, 0.2

# Консеквентні параметри (y = p*x + q)
p1, q1 = 0.0, 0.0
p2, q2 = 0.0, 0.0

# Крок навчання
eta = 0.1

# -------------------------------------------------------------
# 4. Процес навчання
# -------------------------------------------------------------
for epoch in range(100):
    for i in range(len(X)):
        x = X[i]
        y_target = Y[i]

        # Рівень 1: обчислення ступенів приналежності
        mu1 = gauss_mf(x, c1, sigma1)
        mu2 = gauss_mf(x, c2, sigma2)

        # Рівень 2: сила активації правил
        w1, w2 = mu1, mu2

        # Рівень 3: нормалізація сил активації
        w_sum = w1 + w2
        if w_sum == 0:
            continue
        w1n, w2n = w1 / w_sum, w2 / w_sum

        # Рівень 4: вихід кожного правила
        f1 = p1 * x + q1
        f2 = p2 * x + q2

        # Рівень 5: загальний вихід системи
        y_pred = w1n * f1 + w2n * f2

        # Обчислення похибки
        e = y_target - y_pred

        # Оновлення консеквентних параметрів (спрощене навчання)
        p1 += eta * e * w1n * x
        q1 += eta * e * w1n
        p2 += eta * e * w2n * x
        q2 += eta * e * w2n

# -------------------------------------------------------------
# 5. Перевірка результату після навчання
# -------------------------------------------------------------
Y_pred = []
for x in X:
    mu1 = gauss_mf(x, c1, sigma1)
    mu2 = gauss_mf(x, c2, sigma2)
    w_sum = mu1 + mu2
    w1n, w2n = mu1 / w_sum, mu2 / w_sum
    f1 = p1 * x + q1
    f2 = p2 * x + q2
    y = w1n * f1 + w2n * f2
    Y_pred.append(y)

Y_pred = np.array(Y_pred)

# -------------------------------------------------------------
# 6. Візуалізація результату
# -------------------------------------------------------------
plt.figure(figsize=(8, 5))
plt.plot(X, Y, 'b-', label='Цільова функція (sin(πx))')
plt.plot(X, Y_pred, 'r--', label='Вихід ANFIS')
plt.title('Нейро-нечітка апроксимація функції')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------------------------------------
# 7. Вивід підсумкових параметрів
# -------------------------------------------------------------
print("Навчені консеквентні параметри:")
print(f"Правило 1: p1 = {p1:.3f}, q1 = {q1:.3f}")
print(f"Правило 2: p2 = {p2:.3f}, q2 = {q2:.3f}")
